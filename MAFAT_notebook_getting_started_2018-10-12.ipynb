{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with fine-grained image classification\n",
    "\n",
    "This notebook shall go through an idea of beating the benchmark for the MAFAT Challenge using the Classification of Fine-Grained Features In Aerial Image (COFGA) dataset. Initially the study shall replicate the results given in the paper: **Dahan, Eran, and Tzvi Diskin. \"COFGA: Classification Of Fine-Grained Features In Aerial Images.\" arXiv preprint arXiv:1808.09001 (2018).**\n",
    "\n",
    "*Inspired from PyTorch tutorials.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial loading of data and pre-processing steps\n",
    "First we shall load the data, and prepare it for the neural networks.\n",
    "\n",
    "The key steps in pre-processing images is as follows:\n",
    "- Normalising the intensities by subtracting the mean and dividing with 255 on all channels\n",
    "- Ensuring tensor conforms with expected input\n",
    "- Ensuring labels conform with expected output\n",
    "\n",
    "Initially, let us load the data and visualise some of the data in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dataset_v2/train.csv')\n",
    "valid = pd.read_csv('./dataset_v2/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_id                   int64\n",
       "image_id                 int64\n",
       "p1_x                   float64\n",
       "p_1y                   float64\n",
       " p2_x                  float64\n",
       " p2_y                  float64\n",
       " p3_x                  float64\n",
       " p3_y                  float64\n",
       " p4_x                  float64\n",
       " p4_y                  float64\n",
       "general_class           object\n",
       "sub_class               object\n",
       "sunroof                  int64\n",
       "luggage_carrier          int64\n",
       "open_cargo_area          int64\n",
       "enclosed_cab             int64\n",
       "spare_wheel              int64\n",
       "wrecked                  int64\n",
       "flatbed                  int64\n",
       "ladder                   int64\n",
       "enclosed_box             int64\n",
       "soft_shell_box           int64\n",
       "harnessed_to_a_cart      int64\n",
       "ac_vents                 int64\n",
       "color                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tag_id</th>\n",
       "      <td>31658</td>\n",
       "      <td>26971</td>\n",
       "      <td>19301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <td>16490</td>\n",
       "      <td>17122</td>\n",
       "      <td>12193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1_x</th>\n",
       "      <td>3380.8</td>\n",
       "      <td>3948.33</td>\n",
       "      <td>1977.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_1y</th>\n",
       "      <td>33.3709</td>\n",
       "      <td>1426.8</td>\n",
       "      <td>1009.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2_x</th>\n",
       "      <td>3329.81</td>\n",
       "      <td>3958.88</td>\n",
       "      <td>1983.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2_y</th>\n",
       "      <td>128.465</td>\n",
       "      <td>1410.75</td>\n",
       "      <td>992.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3_x</th>\n",
       "      <td>3358.06</td>\n",
       "      <td>4000.67</td>\n",
       "      <td>2034.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3_y</th>\n",
       "      <td>142.936</td>\n",
       "      <td>1438.2</td>\n",
       "      <td>1009.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4_x</th>\n",
       "      <td>3409.06</td>\n",
       "      <td>3990.12</td>\n",
       "      <td>2027.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4_y</th>\n",
       "      <td>44.3964</td>\n",
       "      <td>1454.25</td>\n",
       "      <td>1027.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general_class</th>\n",
       "      <td>large vehicle</td>\n",
       "      <td>small vehicle</td>\n",
       "      <td>small vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_class</th>\n",
       "      <td>truck</td>\n",
       "      <td>sedan</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunroof</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luggage_carrier</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_cargo_area</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enclosed_cab</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spare_wheel</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrecked</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flatbed</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ladder</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enclosed_box</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_shell_box</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harnessed_to_a_cart</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac_vents</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "      <td>silver/grey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 1              2              3\n",
       "tag_id                       31658          26971          19301\n",
       "image_id                     16490          17122          12193\n",
       "p1_x                        3380.8        3948.33         1977.8\n",
       "p_1y                       33.3709         1426.8        1009.01\n",
       " p2_x                      3329.81        3958.88        1983.44\n",
       " p2_y                      128.465        1410.75        992.097\n",
       " p3_x                      3358.06        4000.67        2034.18\n",
       " p3_y                      142.936         1438.2        1009.01\n",
       " p4_x                      3409.06        3990.12        2027.91\n",
       " p4_y                      44.3964        1454.25        1027.18\n",
       "general_class        large vehicle  small vehicle  small vehicle\n",
       "sub_class                    truck          sedan          sedan\n",
       "sunroof                         -1              0              0\n",
       "luggage_carrier                 -1              0              0\n",
       "open_cargo_area                  0              0              0\n",
       "enclosed_cab                    -1              0              0\n",
       "spare_wheel                     -1              0              0\n",
       "wrecked                          0              0              0\n",
       "flatbed                         -1             -1             -1\n",
       "ladder                           0             -1             -1\n",
       "enclosed_box                     1             -1             -1\n",
       "soft_shell_box                   0             -1             -1\n",
       "harnessed_to_a_cart              0             -1             -1\n",
       "ac_vents                        -1             -1             -1\n",
       "color                          red            red    silver/grey"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1:4].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are space and other unwanted characters in the labels. We'll replace these with underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tag_id</th>\n",
       "      <td>31658</td>\n",
       "      <td>26971</td>\n",
       "      <td>19301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <td>16490</td>\n",
       "      <td>17122</td>\n",
       "      <td>12193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1_x</th>\n",
       "      <td>3380.8</td>\n",
       "      <td>3948.33</td>\n",
       "      <td>1977.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_1y</th>\n",
       "      <td>33.3709</td>\n",
       "      <td>1426.8</td>\n",
       "      <td>1009.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2_x</th>\n",
       "      <td>3329.81</td>\n",
       "      <td>3958.88</td>\n",
       "      <td>1983.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2_y</th>\n",
       "      <td>128.465</td>\n",
       "      <td>1410.75</td>\n",
       "      <td>992.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3_x</th>\n",
       "      <td>3358.06</td>\n",
       "      <td>4000.67</td>\n",
       "      <td>2034.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3_y</th>\n",
       "      <td>142.936</td>\n",
       "      <td>1438.2</td>\n",
       "      <td>1009.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4_x</th>\n",
       "      <td>3409.06</td>\n",
       "      <td>3990.12</td>\n",
       "      <td>2027.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4_y</th>\n",
       "      <td>44.3964</td>\n",
       "      <td>1454.25</td>\n",
       "      <td>1027.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general_class</th>\n",
       "      <td>large_vehicle</td>\n",
       "      <td>small_vehicle</td>\n",
       "      <td>small_vehicle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_class</th>\n",
       "      <td>truck</td>\n",
       "      <td>sedan</td>\n",
       "      <td>sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunroof</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luggage_carrier</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_cargo_area</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enclosed_cab</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spare_wheel</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrecked</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flatbed</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ladder</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enclosed_box</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft_shell_box</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harnessed_to_a_cart</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac_vents</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>red</td>\n",
       "      <td>red</td>\n",
       "      <td>silver_grey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 1              2              3\n",
       "tag_id                       31658          26971          19301\n",
       "image_id                     16490          17122          12193\n",
       "p1_x                        3380.8        3948.33         1977.8\n",
       "p_1y                       33.3709         1426.8        1009.01\n",
       " p2_x                      3329.81        3958.88        1983.44\n",
       " p2_y                      128.465        1410.75        992.097\n",
       " p3_x                      3358.06        4000.67        2034.18\n",
       " p3_y                      142.936         1438.2        1009.01\n",
       " p4_x                      3409.06        3990.12        2027.91\n",
       " p4_y                      44.3964        1454.25        1027.18\n",
       "general_class        large_vehicle  small_vehicle  small_vehicle\n",
       "sub_class                    truck          sedan          sedan\n",
       "sunroof                         -1              0              0\n",
       "luggage_carrier                 -1              0              0\n",
       "open_cargo_area                  0              0              0\n",
       "enclosed_cab                    -1              0              0\n",
       "spare_wheel                     -1              0              0\n",
       "wrecked                          0              0              0\n",
       "flatbed                         -1             -1             -1\n",
       "ladder                           0             -1             -1\n",
       "enclosed_box                     1             -1             -1\n",
       "soft_shell_box                   0             -1             -1\n",
       "harnessed_to_a_cart              0             -1             -1\n",
       "ac_vents                        -1             -1             -1\n",
       "color                          red            red    silver_grey"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.replace(' ', '_', regex=True,inplace=True)\n",
    "train.replace('/', '_', regex=True,inplace=True)\n",
    "valid.replace(' ', '_', regex=True,inplace=True)\n",
    "valid.replace('/', '_', regex=True,inplace=True)\n",
    "train[1:4].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MAFAT_Dataset(Dataset):\n",
    "    \"\"\"MAFAT dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.metadata = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = getFileName(name=str(self.metadata.iloc[idx, 1]),filesPath=self.root_dir)\n",
    "        image = io.imread(img_name)\n",
    "        xyPoints = self.metadata.iloc[idx, 2:10].values #xy-coordinates, a maxiumum of 4 objects per image\n",
    "        xyPoints = xyPoints.astype('float').reshape(-1, 2)\n",
    "        xyRaw = self.metadata.iloc[idx, 2:10].values\n",
    "        xyRaw = xyRaw.astype('float')\n",
    "        sample = {'image': image, 'xypoints': xyPoints,'xyRaw': xyRaw,'filename': str(self.metadata.iloc[idx, 1]),\n",
    "                 'tagid': str(self.metadata.iloc[idx, 0]),'OOB_object': 'None'}\n",
    "        \n",
    "        return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./dataset/train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e387c16b0658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m dataset = MAFAT_Dataset(csv_file='./dataset/train.csv',\n\u001b[0;32m---> 61\u001b[0;31m                                     root_dir='dataset/root/train/')\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcopyToClassFolders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistOfClasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrootPath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e9558b38ccd3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_file, root_dir, transform)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \"\"\"\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         self.transform = transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./dataset/train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "\n",
    "def getFileName(filesPath = None,name = None):\n",
    "    \"\"\"\n",
    "    Returns the full name of image given a path and unique string identifying file\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(filesPath):\n",
    "        name = str(name) #ensure\n",
    "        filename = \"\".join(s for s in files if name in s) #get filename in folder\n",
    "        return os.path.join(root, filename) #get full string\n",
    "    \n",
    "def show_landmarks(image, xypoints):\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(xypoints[:, 0], xypoints[:, 1], s=10, marker='.', c='r')\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "\n",
    "def cropIm(im,xvec,yvec,pad,imExtent):\n",
    "    \"\"\"\n",
    "        Crop image\n",
    "    \"\"\"\n",
    "    assert pad >= 0, \"Padding must be positive\"\n",
    "    boxlowx = int(min(xvec)-pad)\n",
    "    boxlowy = int(min(yvec)-pad)\n",
    "    boxhix = int(max(xvec)+pad)\n",
    "    boxhiy = int(max(yvec)+pad)\n",
    "    im = im[boxlowy:boxhiy,boxlowx:boxhix,:] #Ensuring images are square\n",
    "    return im    \n",
    "\n",
    "def cropPolygonImage(image,xvec,yvec,pad,root,filename,pltIm=None,fixedshape=64):\n",
    "    \"\"\"\n",
    "        Crops image based on set of coordinates\n",
    "    \"\"\"\n",
    "    from PIL import Image,ImageDraw\n",
    "    assert image.shape[2] >= 3, 'Image requires alpha layer in forth channel' \n",
    "    polygon = [(xvec[0],yvec[0]),(xvec[1],yvec[1]),(xvec[2],yvec[2]),(xvec[3],yvec[3])]\n",
    "    maskIm = Image.new('L', (image.shape[1], image.shape[0]), 0)\n",
    "    ImageDraw.Draw(maskIm).polygon(polygon, outline=1, fill=1)\n",
    "    mask = np.array(maskIm)\n",
    "\n",
    "    # assemble new image (uint8: 0-255)\n",
    "    newImArray = np.empty(image.shape,dtype='uint8')\n",
    "\n",
    "    # colors (three first columns, RGB)\n",
    "    newImArray[:,:,:3] = image[:,:,:3]\n",
    "\n",
    "    # transparency (4th column)\n",
    "    newImArray[:,:,3] = mask*255\n",
    "\n",
    "    # back to Image from numpy\n",
    "    croppedImage = cropIm(newImArray,xvec=xvec,yvec=yvec,pad=pad,imExtent=fixedshape)\n",
    "    newIm = Image.fromarray(croppedImage, \"RGBA\")\n",
    "    newIm = newIm.resize((256,256),Image.BICUBIC)\n",
    "    newIm.save(osp.join(root,'cropped/',filename))\n",
    "    if pltIm is not None:\n",
    "        plt.imshow(croppedImage)\n",
    "        plt.show()\n",
    "    \n",
    "dataset = MAFAT_Dataset(csv_file='./dataset/train.csv',\n",
    "                                    root_dir='dataset/root/train/')\n",
    "\n",
    "def copyToClassFolders(listOfClasses,rootPath=None,df=None):\n",
    "    \"\"\"\n",
    "        Copies cropped images and assigns them to folder representative of that feature/class\n",
    "    \"\"\"\n",
    "    import shutil\n",
    "    import difflib\n",
    "    list_of_cropped_images=os.listdir(rootPath+'cropped/')\n",
    "    ims = 0\n",
    "    errorIm=0\n",
    "    classCols=df.columns[12:-1]\n",
    "    for image in list_of_cropped_images: # loop over the cropped images\n",
    "        s = str(image)\n",
    "        s = s.replace('.png','')\n",
    "        s = s.split('_') #split into image_id and tag_id\n",
    "        try:\n",
    "            dataRow = df[df.tag_id == int(s[1])]\n",
    "        except:\n",
    "            print('unexpected file type')\n",
    "            continue\n",
    "        if not dataRow.empty:\n",
    "            feat = dataRow #get only the  class features\n",
    "            for i in range(10,25):\n",
    "                val = feat.iloc[0,i]\n",
    "                if isinstance(val,str) is True: #type of general class\n",
    "                    shutil.copy2(rootPath+'cropped/'+image, rootPath+'classes/'+val) \n",
    "                if i > 11  and i < 24:            \n",
    "                    if int(val) > 0:\n",
    "                        item = i-12\n",
    "                        match = difflib.get_close_matches(str(classCols[item]),listOfClasses,n=1)[0]\n",
    "                        shutil.copy2(rootPath+'cropped/'+image, rootPath+'classes/'+match)\n",
    "        else:\n",
    "            errorIm+=1\n",
    "            if errorIm % 100 ==0:\n",
    "                print(errorIm)\n",
    "        ims+=1\n",
    "        if ims % 250 == 0:\n",
    "            print(f'Images copied: {ims}')                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize 5 tagged objects\n",
    "numTags = 5\n",
    "for i in range(0,5):\n",
    "    show_landmarks(dataset[i]['image'],xypoints=dataset[i]['xypoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateCroppedImages(dataset,imDir,pltIm=None):\n",
    "    \"\"\"\n",
    "    Generates cropped images based on bounding box presented as a tag_id\n",
    "    args:\n",
    "        input: \n",
    "                dataset - Dataset of the MAFAT_Dataset class\n",
    "                imDir - Root of all images \n",
    "                pltIm - If true plots cropped result\n",
    "                \n",
    "    \"\"\"\n",
    "    i=0\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(f'{imDir}/cropped/'):\n",
    "        os.makedirs(f'{imDir}/cropped/')\n",
    "    \n",
    "    for entry in dataset:\n",
    "        entry = dataset[i]\n",
    "        filename = entry['filename']+'_'+entry['tagid']+'.png'\n",
    "        xy = entry['xyRaw']\n",
    "        imnext = entry['image']\n",
    "        imnext = np.concatenate((imnext,np.ones(imnext.shape[:-1]+(1,))*255),axis=-1) ## Add alpha for polygon cropping\n",
    "        xvec = [xy[0],xy[2],xy[4],xy[6]]\n",
    "        yvec = [xy[1],xy[3],xy[5],xy[7]]\n",
    "        \n",
    "        try:\n",
    "            cropPolygonImage(imnext,xvec,yvec,0,imDir,filename=filename,pltIm=pltIm)\n",
    "        except:\n",
    "            print('Warning: Object out of bounds, filename: %s',filename,'\\n Iteration no:',i)\n",
    "            dataset[i]['OOB_object'] = filename\n",
    "        i+=1\n",
    "        if i % 100 == 0:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = MAFAT_Dataset(csv_file='./dataset_v2/train.csv',root_dir='dataset_v2/root/train/')\n",
    "imDir = './dataset_v2/root/train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note the next operation takes quite a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateCroppedImages(dataset=dataset,imDir=imDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the cropped results\n",
    "The outputted cropped images are hereafter located in the 'cropped/'-folder\n",
    "We can visualize how the expected results should look like by examining the following plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " show_landmarks(dataset[53]['image'],xypoints=dataset[53]['xypoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " show_landmarks(dataset[54]['image'],xypoints=dataset[54]['xypoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " show_landmarks(dataset[52]['image'],xypoints=dataset[52]['xypoints'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such that for each of the above tags, we crop the .TIF files into smaller .PNG files representative of the extent form by the four point coordinates given by the tag. One should try and play around with dilation, since it is aparaent that in some cases the extent of the polygon is too tight. \n",
    "\n",
    "Futhermore, several of the annotated objects cross boundaries with other .TIF files. This is not handled at the moment, and such tags are simply excluded from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = dataset[i]\n",
    "filename = entry['filename']+'_'+entry['tagid']+'.png'\n",
    "xy = entry['xyRaw']\n",
    "imnext = entry['image']\n",
    "imnext = np.concatenate((imnext,np.ones(imnext.shape[:-1]+(1,))*255),axis=-1) ## Add alpha for polygon cropping\n",
    "\n",
    "xvec = [xy[0],xy[2],xy[4],xy[6]]\n",
    "yvec = [xy[1],xy[3],xy[5],xy[7]]\n",
    "cropPolygonImage(imnext,xvec,yvec,0,'./dataset/root/train/',filename=filename,pltIm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputting images into class folders\n",
    "\n",
    "Now that the images are cropped, we may organise each of the tagged objects into folder representative of the class and feature combinations formed by the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_cropped_images=os.listdir('./dataset_v2/root/train/cropped/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all classes/features \n",
    "listOfClasses = train.iloc[:,10].unique().tolist()\n",
    "listOfClasses.extend(train.iloc[:,11].unique().tolist())\n",
    "listOfClasses.extend(train.columns[12:-1].tolist())\n",
    "listOfClasses.extend(train.iloc[:,-1].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootPath = './dataset_v2/root/train/classes/'\n",
    "os.mkdir(rootPath)\n",
    "for cls in listOfClasses:\n",
    "    os.mkdir(f'{rootPath}{cls}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy images to folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyToClassFolders(listOfClasses,rootPath='./dataset_v2/root/train/',df=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all folders should have a file corresponding to the class/feature combination it matches. The same procedure should be completed with the validation .CSV file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
