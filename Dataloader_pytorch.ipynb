{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from libcpab.libcpab.pytorch import cpab\n",
    "from libcpab.libcpab.helper.utility import show_images\n",
    "from IPython.display import display\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from skimage import io\n",
    "from skimage.transform import rescale\n",
    "from skimage.transform import resize\n",
    "import datetime\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Construct Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineGrainedDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_path, picturesize, transform=True):\n",
    "        \"\"\"\n",
    "        Construct Fine Grained Dataset.\n",
    "        \n",
    "        Args\n",
    "            csv_path: Path to CSV file.\n",
    "            picturesize: Dimensions of sample images.\n",
    "            transform: \n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.picturesize = picturesize\n",
    "        \n",
    "        # construct dataframe with onehot notation\n",
    "        self.df = pd.get_dummies(pd.read_csv(csv_path))\n",
    "        # create ID column with image file names\n",
    "        self.df['id'] = self.df['image_id'].apply(lambda x: str(x)) + \"_\" + self.df['tag_id'].apply(lambda x: str(x)) + \".png\"\n",
    "        # only use class columns and id column\n",
    "        self.df = self.df.iloc[:, 10:]\n",
    "        \n",
    "        self.path = '/Users/mattias/Desktop/cropped/'\n",
    "            \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Support integer indexing on dataset (range 0 to len(self)).\n",
    "        \"\"\"\n",
    "        sample_id = self.df['id'].iloc[idx]\n",
    "        \n",
    "        # get target values for sample\n",
    "        targets = self.df.loc[idx, self.df.columns != 'id'].values.astype('float32')\n",
    "        \n",
    "        # get sample image\n",
    "        image = np.asarray(Image.open(self.path + sample_id))\n",
    "        \n",
    "        # transform sample\n",
    "        if self.transform:\n",
    "            img = image\n",
    "            img_normalized = np.copy(img)\n",
    "            img_normalized = img_normalized / 255.\n",
    "            \n",
    "            img_resized = resize(img_normalized, output_shape=(self.picturesize,self.picturesize), mode='reflect', anti_aliasing=True)[:,:,:3]\n",
    "            \n",
    "            sample = {'id': sample_id, 'targets': torch.from_numpy(targets), 'image': torch.from_numpy(img_resized)}\n",
    "        else:\n",
    "            sample = {'id': sample_id, 'targets': targets, 'image': image}\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sunroof</th>\n",
       "      <th>luggage_carrier</th>\n",
       "      <th>open_cargo_area</th>\n",
       "      <th>enclosed_cab</th>\n",
       "      <th>spare_wheel</th>\n",
       "      <th>wrecked</th>\n",
       "      <th>flatbed</th>\n",
       "      <th>ladder</th>\n",
       "      <th>enclosed_box</th>\n",
       "      <th>soft_shell_box</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_class_van</th>\n",
       "      <th>color_black</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_other</th>\n",
       "      <th>color_red</th>\n",
       "      <th>color_silver/grey</th>\n",
       "      <th>color_white</th>\n",
       "      <th>color_yellow</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16490_15036.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16490_31658.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17122_26971.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12193_19301.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12193_35906.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sunroof  luggage_carrier  open_cargo_area  enclosed_cab  spare_wheel  \\\n",
       "0        0                0                0             0            0   \n",
       "1       -1               -1                0            -1           -1   \n",
       "2        0                0                0             0            0   \n",
       "3        0                0                0             0            0   \n",
       "4       -1               -1                0            -1           -1   \n",
       "\n",
       "   wrecked  flatbed  ladder  enclosed_box  soft_shell_box       ...         \\\n",
       "0        0        0       0             0               0       ...          \n",
       "1        0       -1       0             1               0       ...          \n",
       "2        0       -1      -1            -1              -1       ...          \n",
       "3        0       -1      -1            -1              -1       ...          \n",
       "4        0        1       0             0               0       ...          \n",
       "\n",
       "   sub_class_van  color_black  color_blue  color_green  color_other  \\\n",
       "0              0            1           0            0            0   \n",
       "1              0            0           0            0            0   \n",
       "2              0            0           0            0            0   \n",
       "3              0            0           0            0            0   \n",
       "4              0            0           0            0            0   \n",
       "\n",
       "   color_red  color_silver/grey  color_white  color_yellow               id  \n",
       "0          0                  0            0             0  16490_15036.png  \n",
       "1          1                  0            0             0  16490_31658.png  \n",
       "2          1                  0            0             0  17122_26971.png  \n",
       "3          0                  1            0             0  12193_19301.png  \n",
       "4          1                  0            0             0  12193_35906.png  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = FineGrainedDataset(csv_path='./data/dataset_v2/train.csv', picturesize=224, transform=True)\n",
    "dataset.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /Users/mattias/.torch/models/resnet50-19c8e357.pth\n",
      "100%|██████████| 102502400/102502400 [01:09<00:00, 1470333.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (output): Linear(in_features=1024, out_features=37, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model\n",
    "model_conv = models.resnet50(pretrained='imagenet')\n",
    "\n",
    "# Disable autograd for resnet\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Change fully connected layer to match paper (autograd is default on new layers)\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 1024)\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.output = nn.Linear(1024, num_classes)\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = model_conv(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.output(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(num_classes=37).to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 37])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test forward pass\n",
    "x = np.random.uniform(0, 1, size=(10, 3, 224, 224)).astype('float32')\n",
    "x = torch.autograd.Variable(torch.from_numpy(x))\n",
    "\n",
    "out = net(x.to(device))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in provided dataset: 11617\n",
      "\n",
      "Split criteria\n",
      "train size: 80.00 %\n",
      "valid size: 20.00 %\n",
      "\n",
      "Split results\n",
      "Train size:\t9281\t(79.89 %)\n",
      "Val size:\t2336\t(20.11 %)\n"
     ]
    }
   ],
   "source": [
    "def train_valid_split(df, trainsplit_size=0.8):\n",
    "    \"\"\"\n",
    "    Split a dataset in training- and validation split.\n",
    "\n",
    "    Split is made by splitting the least represented class first\n",
    "    and the highest represented class last.\n",
    "\n",
    "    Function is made for multilabel problems where samples that are already \n",
    "    drawn from a previous class are not drawn again, and the ratio of the \n",
    "    split is calculated at each class from the previous draws to match the \n",
    "    split criteria.\n",
    "\n",
    "    Args\n",
    "        df: A dataframe which the split should be created from.\n",
    "            The indexes should be the ID's of the samples.\n",
    "        trainsplit_size: The size of the training split. \n",
    "                         Should be a float in the interval [0, 1]\n",
    "    \"\"\"\n",
    "    # placeholders\n",
    "    cls = {}\n",
    "    train_idx = []\n",
    "    valid_idx = []\n",
    "    \n",
    "    df_cls = df.loc[:, df.columns != 'id']\n",
    "\n",
    "    # get number of occurrences for each class\n",
    "    for col in df_cls:\n",
    "        size = len(df_cls.loc[df_cls[col] == 1])\n",
    "        cls[col] = size\n",
    "\n",
    "    # sort classes by ascending\n",
    "    cls_sorted = sorted(cls.items(), key=lambda value: value[1])\n",
    "\n",
    "    # iterate over classes from least represented class\n",
    "    # and draw samples for training- and validation split\n",
    "    for col in cls_sorted:\n",
    "        # get indexes for samples where class value is 1\n",
    "        indexes = df_cls.loc[df_cls[col[0]] == 1].index\n",
    "\n",
    "        # Remove indexes that already are appended to test_idx array\n",
    "        indexes = [indexes[i] for i in range(len(indexes)) if indexes[i] not in valid_idx and indexes[i] not in train_idx]\n",
    "\n",
    "        # get size of how many indexes should be drawn for train\n",
    "        train_size = int(len(indexes) * trainsplit_size)\n",
    "\n",
    "        # get indexes for train- and validation split\n",
    "        idx_train = [indexes[i] for i in sorted(random.sample(range(len(indexes)), train_size))]\n",
    "        idx_valid = [indexes[i] for i in range(len(indexes)) if indexes[i] not in idx_train]\n",
    "\n",
    "        # save indexes\n",
    "        train_idx.extend(idx_train)\n",
    "        valid_idx.extend(idx_valid)\n",
    "        \n",
    "    print(\"Number of samples in provided dataset: {}\\n\".format(len(df_cls)))\n",
    "    print(\"Split criteria\\ntrain size: {:.2f} %\\nvalid size: {:.2f} %\".format(trainsplit_size*100, \n",
    "                                                                   (1-trainsplit_size)*100))\n",
    "    print(\"\\nSplit results\")\n",
    "    print(\"Train size:\\t{}\\t({:.2f} %)\".format(len(train_idx), \\\n",
    "                                               (len(train_idx) / len(df_cls)) * 100))\n",
    "    print(\"Val size:\\t{}\\t({:.2f} %)\".format(len(valid_idx), \\\n",
    "                                     (len(valid_idx) / len(df_cls)) * 100))\n",
    "\n",
    "    return train_idx, valid_idx\n",
    "\n",
    "train_indexes, valid_indexes = train_valid_split(dataset.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "trainsampler = SubsetRandomSampler(train_indexes)\n",
    "validsampler = SubsetRandomSampler(valid_indexes)\n",
    "\n",
    "samplers = {'train': trainsampler,\n",
    "            'valid': validsampler}\n",
    "\n",
    "trainloader = DataLoader(dataset=dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         sampler=samplers['train'],\n",
    "                         num_workers=4)\n",
    "validloader = DataLoader(dataset=dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         sampler=samplers['valid'],\n",
    "                         num_workers=4)\n",
    "\n",
    "dataloaders = {'train': trainloader,\n",
    "               'valid': validloader}\n",
    "\n",
    "dataset_sizes = {x: len(samplers[x]) for x in ['train', 'valid']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "threshold = 0.5\n",
    "valid_every = 2\n",
    "\n",
    "losses_train = pd.DataFrame(columns=['Epoch','Loss'])\n",
    "losses_valid = pd.DataFrame(columns=['Epoch','Loss'])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    net.train()\n",
    "    \n",
    "    for batch in dataloaders['train']:\n",
    "        inputs = batch['image'].permute(0, 3, 1, 2)\n",
    "        labels = batch['targets']\n",
    "        inputs, labels = inputs.to(device, dtype=torch.float), labels.to(device, dtype=torch.float)\n",
    "    \n",
    "    \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # Make prediction and backpropogate\n",
    "        output = net(inputs)\n",
    "        loss = criterion(output,labels)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "        \n",
    "    # calculate the loss of the training set   \n",
    "    losses_train.loc[epoch] = [epoch+1,np.mean(batch_loss)]\n",
    "    \n",
    "    if epoch % valid_every == 0 or epoch == max(range(epochs)):\n",
    "        batch_loss = []\n",
    "        preds = []\n",
    "        trues = []\n",
    "        net.eval()\n",
    "        \n",
    "        for batch in dataloaders['valid']:\n",
    "            inputs = batch['image'].permute(0, 3, 1, 2)\n",
    "            labels = batch['targets']\n",
    "            inputs, labels = inputs.to(device, dtype=torch.float), labels.to(device, dtype=torch.float)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Make prediction\n",
    "            output = net(inputs)\n",
    "            loss = criterion(output,labels)\n",
    "            batch_loss.append(loss.item())\n",
    "            \n",
    "            # Append values for later calculation of accuracy\n",
    "            preds.append([[1 if pred > threshold else 0 for pred in sample] for sample in output])\n",
    "            trues.append([[int(value) for value in valuelist] for valuelist in labels.tolist()])\n",
    "        \n",
    "        # Calculate loss and accuracy for the validation set    \n",
    "        losses_valid.loc[epoch] = [epoch+1,np.mean(batch_loss)]\n",
    "        accuracy = MAP(preds[0], trues[0])\n",
    "        \n",
    "    # Plot the loss every epoch\n",
    "    pl.figure(figsize=(15,5))\n",
    "    pl.xlabel('Epochs')\n",
    "    pl.ylabel('Loss')\n",
    "    pl.title('Epoch #{}'.format(epoch+1))\n",
    "    pl.plot(losses_train['Epoch'],losses_train['Loss'], '-b', label='Train')\n",
    "    pl.plot(losses_valid['Epoch'],losses_valid['Loss'], '-r', label='Valid')\n",
    "    pl.legend()\n",
    "    pl.show()\n",
    "    print('Training loss: {:.2f}'.format(losses_train['Loss'].iloc[-1],))\n",
    "    print('Validation loss:{:.2f}\\tValidation MAP: {:.2f}'.format(losses_valid['Loss'].iloc[-1],accuracy))\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "\n",
    "# Final plot    \n",
    "pl.figure(figsize=(15,5))\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Loss')\n",
    "pl.title('Epoch #{}'.format(epoch+1))\n",
    "pl.plot(losses_train['Epoch'],losses_train['Loss'], '-b', label='Train')\n",
    "pl.plot(losses_valid['Epoch'],losses_valid['Loss'], '-r', label='Valid')\n",
    "pl.legend()\n",
    "pl.show()\n",
    "\n",
    "print('Training loss: {:.2f}'.format(losses_train['Loss'].iloc[-1],))\n",
    "print('Validation loss:{:.2f}\\tValidation MAP: {:.2f}'.format(losses_valid['Loss'].iloc[-1],accuracy))\n",
    "\n",
    "print(\"\\n\\t\\t\\t\\t\\tTraining time {}\".format(datetime.datetime.now()-now))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
